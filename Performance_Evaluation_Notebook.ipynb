{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Evaluation Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "[nltk_data] Downloading package wordnet to /home/jota/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "import os\n",
    "import pandas as pd\n",
    "from models.languageModels.translationModels import *\n",
    "from models.learningModels import learningKerasModels\n",
    "from utils.utils import *\n",
    "from utils import generators\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import optimizers\n",
    "from collections import defaultdict\n",
    "import tensorflow as tf\n",
    "from utils import jiwer\n",
    "#from utils import evaluation\n",
    "from utils import bleu\n",
    "from utils import rouge\n",
    "import main\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import single_meteor_score\n",
    "import nltk\n",
    "import copy\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7096\n",
      "train rouge 12.382089768228814\n",
      "train WER 111.61264240565383\n",
      "train Meteor 9.605041925211696\n",
      "train bleu 1 14.540281609910316\n",
      "train bleu 2 6.655631857839774\n",
      "train bleu 3 3.864429248433179\n",
      "train bleu 4 2.6301798126849016\n",
      "642\n",
      "test rouge 11.532112772508134\n",
      "test WER 116.68140808412608\n",
      "test Meteor 9.013053143051897\n",
      "test bleu 1 14.098855489875486\n",
      "test bleu 2 6.6608072558548965\n",
      "test bleu 3 4.144581078293574\n",
      "test bleu 4 2.993728489341203\n",
      "519\n",
      "dev rouge 12.36314307351333\n",
      "dev WER 110.63273458307694\n",
      "dev Meteor 9.506925402137815\n",
      "dev bleu 1 14.741156566901905\n",
      "dev bleu 2 6.710022673659551\n",
      "dev bleu 3 4.036408024659126\n",
      "dev bleu 4 2.872527497369305\n"
     ]
    }
   ],
   "source": [
    "# Translation file to evaluate\n",
    "results = open(os.getcwd()+'/results/translations/EXTRA2-PHOENIX-RGB-LSTM-TOP-128-60.pkl',\"rb\")\n",
    "results = pickle.load(results)\n",
    "\n",
    "def metrics_on_corpus(result):\n",
    "    annotations ='../Datasets/Pre-procesados/SLR/RWTH-Phoenix/phoenixT/phoenix-2014-T.v3/PHOENIX-2014-T-release-v3/PHOENIX-2014-T/annotations/'\n",
    "    ann = pd.read_csv(annotations+'annotations.csv', delimiter='|')\n",
    "    \n",
    "    for data in result.keys():\n",
    "        references = []\n",
    "        translations = []\n",
    "        references_rouge = []\n",
    "        translations_rouge = []\n",
    "        wert = 0.0\n",
    "        meteort = 0.0\n",
    "        for c, name in enumerate(result[data].keys()):\n",
    "            translation = result[data][name][0]\n",
    "            videoName = name.split('.')[0]#[:11]\n",
    "            reference = ann['Translation'][ann['Video Name']==videoName].values[0].lower()\n",
    "            if len(translation)==1:\n",
    "                flag=True\n",
    "            else:\n",
    "                flag=False\n",
    "            if '<eos>' in translation:\n",
    "                translation.remove('<eos>')\n",
    "            translation = \" \".join(translation)\n",
    "            wert = wert + jiwer.wer(truth = reference, hypothesis = translation) \n",
    "            meteort = meteort + single_meteor_score(reference, translation)\n",
    "            \n",
    "            translations.append(translation.split(\" \"))\n",
    "            translations_rouge.append(translation)\n",
    "            references.append([reference.split(\" \")])\n",
    "            references_rouge.append(reference)\n",
    "            \n",
    "        print(len(references))\n",
    "        rouge_score_map = rouge.rouge(translations_rouge, references_rouge)\n",
    "        print(data, 'rouge', 100 * rouge_score_map[\"rouge_l/f_score\"])\n",
    "        print(data , 'WER', (wert/len(references))*100)\n",
    "        print(data , 'Meteor', (meteort/len(references))*100)\n",
    "        for max_ in range(1,5):\n",
    "            bleu_score, _, _, _, _, _ = bleu.compute_bleu(references, translations, max_order=max_)\n",
    "            print(data, 'bleu',max_,bleu_score*100)\n",
    "        \n",
    "            \n",
    "metrics_on_corpus(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
